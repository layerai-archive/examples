{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  },
  "colab": {
   "name": "convolutional-neural-network-cnn-ima.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Network (CNN) - Image Classification"
   ],
   "metadata": {
    "id": "XYn7v0Vg6bfi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[![Open in Layer](https://development.layer.co/assets/badge.svg)](https://app.layer.ai/layer/image-classification) [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/layerai/examples/blob/main/food-vision/food-vision.ipynb) [![Layer Examples Github](https://badgen.net/badge/icon/github?icon=github&label)](https://github.com/layerai/examples/tree/main/food-vision)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install layer -qqq"
   ],
   "metadata": {
    "id": "gFo95gq9YOGc",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "09fd994c-63e4-43a1-9815-36b8cd1ef198"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001B[?25l\r\u001B[K     |▊                               | 10 kB 24.2 MB/s eta 0:00:01\r\u001B[K     |█▍                              | 20 kB 17.2 MB/s eta 0:00:01\r\u001B[K     |██                              | 30 kB 10.7 MB/s eta 0:00:01\r\u001B[K     |██▊                             | 40 kB 4.0 MB/s eta 0:00:01\r\u001B[K     |███▌                            | 51 kB 2.5 MB/s eta 0:00:01\r\u001B[K     |████▏                           | 61 kB 2.9 MB/s eta 0:00:01\r\u001B[K     |████▉                           | 71 kB 3.4 MB/s eta 0:00:01\r\u001B[K     |█████▌                          | 81 kB 3.8 MB/s eta 0:00:01\r\u001B[K     |██████▎                         | 92 kB 4.3 MB/s eta 0:00:01\r\u001B[K     |███████                         | 102 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████▋                        | 112 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |████████▎                       | 122 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████                       | 133 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████▊                      | 143 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |██████████▍                     | 153 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████████                     | 163 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████████▊                    | 174 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |████████████▌                   | 184 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████████▏                  | 194 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████████▉                  | 204 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |██████████████▌                 | 215 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████████████▏                | 225 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |████████████████                | 235 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |████████████████▋               | 245 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████████████▎              | 256 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |██████████████████              | 266 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |██████████████████▊             | 276 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████████████████▍            | 286 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |████████████████████            | 296 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |████████████████████▊           | 307 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████████████████▍          | 317 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |██████████████████████▏         | 327 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |██████████████████████▉         | 337 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████████████████████▌        | 348 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |████████████████████████▏       | 358 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████████████████████       | 368 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████████████████████▋      | 378 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |██████████████████████████▎     | 389 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████     | 399 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████▋    | 409 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████▍   | 419 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████   | 430 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |█████████████████████████████▊  | 440 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |██████████████████████████████▍ | 450 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████▏| 460 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |███████████████████████████████▉| 471 kB 4.4 MB/s eta 0:00:01\r\u001B[K     |████████████████████████████████| 473 kB 4.4 MB/s \n",
      "\u001B[K     |████████████████████████████████| 40 kB 5.0 MB/s \n",
      "\u001B[K     |████████████████████████████████| 97 kB 4.4 MB/s \n",
      "\u001B[K     |████████████████████████████████| 256 kB 62.2 MB/s \n",
      "\u001B[K     |████████████████████████████████| 56 kB 3.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 1.3 MB 50.9 MB/s \n",
      "\u001B[K     |████████████████████████████████| 271 kB 43.2 MB/s \n",
      "\u001B[K     |████████████████████████████████| 2.4 MB 5.5 MB/s \n",
      "\u001B[K     |████████████████████████████████| 212 kB 41.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 132 kB 46.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 4.4 MB 33.5 MB/s \n",
      "\u001B[K     |████████████████████████████████| 381 kB 40.6 MB/s \n",
      "\u001B[K     |████████████████████████████████| 26.7 MB 1.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 159 kB 50.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 4.0 MB 9.6 MB/s \n",
      "\u001B[K     |████████████████████████████████| 16.8 MB 674 kB/s \n",
      "\u001B[K     |████████████████████████████████| 3.6 MB 29.4 MB/s \n",
      "\u001B[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
      "\u001B[K     |████████████████████████████████| 94 kB 1.6 MB/s \n",
      "\u001B[K     |████████████████████████████████| 8.7 MB 11.4 MB/s \n",
      "\u001B[K     |████████████████████████████████| 79 kB 7.0 MB/s \n",
      "\u001B[K     |████████████████████████████████| 138 kB 42.1 MB/s \n",
      "\u001B[K     |████████████████████████████████| 146 kB 56.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 596 kB 44.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 62 kB 659 kB/s \n",
      "\u001B[K     |████████████████████████████████| 79 kB 6.7 MB/s \n",
      "\u001B[K     |████████████████████████████████| 210 kB 71.7 MB/s \n",
      "\u001B[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
      "\u001B[K     |████████████████████████████████| 127 kB 58.8 MB/s \n",
      "\u001B[K     |████████████████████████████████| 51 kB 4.4 MB/s \n",
      "\u001B[K     |████████████████████████████████| 78 kB 6.4 MB/s \n",
      "\u001B[K     |████████████████████████████████| 6.6 MB 37.4 MB/s \n",
      "\u001B[K     |████████████████████████████████| 77 kB 4.7 MB/s \n",
      "\u001B[K     |████████████████████████████████| 895 kB 57.4 MB/s \n",
      "\u001B[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/b8/ab/c7abc950e222c4cab5f7fd92107f3b09553061f673f1a670e6569105f584/grpcio-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=cc135b77f384a84bac67a37947886986be136356446338d64160a30c85f20c6d (from https://pypi.org/simple/grpcio/) (requires-python:>=3.6))\n",
      "Reason for being yanked: Segfaults\u001B[0m\n",
      "\u001B[33mWARNING: The candidate selected for download or install is a yanked version: 'grpcio-tools' candidate (version 1.45.0 at https://files.pythonhosted.org/packages/be/e1/70dac693e6df7e4f3108dfd3a82f86f0cd3742d9afe98bb2fe4333a3edd7/grpcio_tools-1.45.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=7db11a65e07410db1c31cbeb9afe344a6bd88a63dcd819557707ca7318478727 (from https://pypi.org/simple/grpcio-tools/) (requires-python:>=3.6))\n",
      "Reason for being yanked: grpcio 1.45.0 was yanked\u001B[0m\n",
      "\u001B[?25h  Building wheel for validate-email (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Building wheel for polling (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
      "nbclient 0.6.0 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
      "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
      "ipython 5.5.0 requires prompt-toolkit<2.0.0,>=1.0.4, but you have prompt-toolkit 3.0.29 which is incompatible.\n",
      "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import layer\n",
    "from layer.decorators import model, fabric,pip_requirements"
   ],
   "metadata": {
    "id": "4mAdGAWAYOGd",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:40:03.867739Z",
     "iopub.execute_input": "2022-04-24T15:40:03.868001Z",
     "iopub.status.idle": "2022-04-24T15:40:03.871598Z",
     "shell.execute_reply.started": "2022-04-24T15:40:03.867976Z",
     "shell.execute_reply": "2022-04-24T15:40:03.870965Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "layer.login()"
   ],
   "metadata": {
    "id": "tZ0uKzJyYOGd",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:40:04.682609Z",
     "iopub.execute_input": "2022-04-24T15:40:04.683017Z",
     "iopub.status.idle": "2022-04-24T15:40:25.149686Z",
     "shell.execute_reply.started": "2022-04-24T15:40:04.682973Z",
     "shell.execute_reply": "2022-04-24T15:40:25.1482Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5427d89f-0016-4697-8343-16811077f297"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Please open the following link in your web browser. Once logged in, copy the code and paste it here.\n",
      "https://auth.app.layer.ai/authorize?response_type=code&code_challenge=0giISng_VLMLjYh7dmbFihy5IQqyNrdo0Q7vL3QlQXk&code_challenge_method=S256&client_id=0STDdcnpK48P8A429EAAn93WNuLmViLR&redirect_uri=https://app.layer.ai/oauth/code&scope=offline_access&audience=https://app.layer.ai\n",
      "Code: j51gD0vNLmhIBqDHRIkCMKOd3I7O3ad9PUHHMYy7WH_7H\n",
      "Successfully logged into https://app.layer.ai\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "layer.init(\"image-classification\")"
   ],
   "metadata": {
    "id": "tq6yTgnxYOGd",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:41:12.658776Z",
     "iopub.execute_input": "2022-04-24T15:41:12.659074Z",
     "iopub.status.idle": "2022-04-24T15:41:13.169253Z",
     "shell.execute_reply.started": "2022-04-24T15:41:12.659046Z",
     "shell.execute_reply": "2022-04-24T15:41:13.168024Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4bb4efb2-925c-48ef-b8c6-df005e7beda7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Project(name='image-classification', raw_datasets=[], derived_datasets=[], models=[], path=PosixPath('.'), project_files_hash='', readme='', account=Account(id=UUID('add1b570-c8e7-4187-b747-1d01104893a9'), name='layer'), _id=UUID('5505a21d-f3ef-4676-bf38-faf333790ee0'), functions=[])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pip install wget"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-24T15:41:51.929365Z",
     "iopub.execute_input": "2022-04-24T15:41:51.929631Z",
     "iopub.status.idle": "2022-04-24T15:42:02.547896Z",
     "shell.execute_reply.started": "2022-04-24T15:41:51.929602Z",
     "shell.execute_reply": "2022-04-24T15:42:02.54727Z"
    },
    "trusted": true,
    "id": "TypPFTJ2Mnhn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@pip_requirements(packages=[\"wget\",\"tensorflow\",\"keras\"])\n",
    "@fabric(\"f-gpu-small\")\n",
    "@model(name=\"food-vision\")\n",
    "def train():\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import Sequential\n",
    "    from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt \n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import tarfile\n",
    "    import wget\n",
    "    wget.download(\"http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\")\n",
    "    food_tar = tarfile.open('food-101.tar.gz')\n",
    "    food_tar.extractall('.') \n",
    "    food_tar.close()\n",
    "    plt.imshow(Image.open(\"food-101/images/beignets/2802124.jpg\"))\n",
    "    plt.axis('off')\n",
    "    layer.log({\"Sample image\":plt.gcf()})\n",
    "    base_dir = 'food-101/images'\n",
    "    class_names = os.listdir(base_dir)\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   validation_split=0.2\n",
    "                                   )\n",
    "    validation_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
    "    image_size = (200, 200)\n",
    "    training_set = train_datagen.flow_from_directory(base_dir,\n",
    "                                                 seed=101,                                                 \n",
    "                                                 target_size=image_size,\n",
    "                                                 batch_size=32,\n",
    "                                                 subset = \"training\",\n",
    "                                                 class_mode='categorical')\n",
    "    validation_set = validation_gen.flow_from_directory(base_dir, \n",
    "                                               target_size=image_size,\n",
    "                                               batch_size=32, \n",
    "                                               subset = \"validation\",\n",
    "                                               class_mode='categorical')\n",
    "    model = Sequential([\n",
    "            \n",
    "    Conv2D(filters=32,kernel_size=(3,3),  input_shape = (200, 200, 3),activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(filters=32,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(filters=64,kernel_size=(3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Dense(101, activation='softmax')])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "    callback = EarlyStopping(monitor='loss', patience=3)\n",
    "    epochs=10\n",
    "    history = model.fit(training_set,validation_data=validation_set, epochs=epochs,callbacks=[callback])\n",
    "    metrics_df = pd.DataFrame(history.history)\n",
    "    layer.log({\"Metrics\":metrics_df})\n",
    "    loss, accuracy = model.evaluate(validation_set)\n",
    "    layer.log({\"Accuracy on test dataset\":accuracy})\n",
    "    metrics_df[[\"loss\",\"val_loss\"]].plot()\n",
    "    layer.log({\"Loss plot\":plt.gcf()})\n",
    "    metrics_df[[\"categorical_accuracy\",\"val_categorical_accuracy\"]].plot()\n",
    "    layer.log({\"Accuracy plot\":plt.gcf()})\n",
    "    return model"
   ],
   "metadata": {
    "id": "6NeNa9KIYOGe",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:42:06.180692Z",
     "iopub.execute_input": "2022-04-24T15:42:06.180986Z",
     "iopub.status.idle": "2022-04-24T15:42:06.208236Z",
     "shell.execute_reply.started": "2022-04-24T15:42:06.180956Z",
     "shell.execute_reply": "2022-04-24T15:42:06.206469Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Run Layer infra\n",
    "layer.run([train],debug=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-04-24T15:42:10.157203Z",
     "iopub.execute_input": "2022-04-24T15:42:10.15748Z"
    },
    "trusted": true,
    "id": "E-mRkxXsMnhq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Run locally\n",
    "train()"
   ],
   "metadata": {
    "id": "J8MsHfqkYOGf",
    "execution": {
     "iopub.status.busy": "2022-04-24T15:41:21.254046Z",
     "iopub.execute_input": "2022-04-24T15:41:21.25484Z",
     "iopub.status.idle": "2022-04-24T15:41:25.146901Z",
     "shell.execute_reply.started": "2022-04-24T15:41:21.254806Z",
     "shell.execute_reply": "2022-04-24T15:41:25.144825Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "image_model = layer.get_model('layer/image-classification/models/food-vision').get_train()\n",
    "!wget --no-check-certificate \\\n",
    "    https://upload.wikimedia.org/wikipedia/commons/b/b1/Buttermilk_Beignets_%284515741642%29.jpg \\\n",
    "    -O /tmp/Buttermilk_Beignets_.jpg"
   ],
   "metadata": {
    "id": "_2xpN6wgYOGf",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image = image.load_img('/tmp/Buttermilk_Beignets_.jpg', target_size=(200, 200))"
   ],
   "metadata": {
    "id": "5sssJ6THYOGf",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image = image.img_to_array(test_image)\n"
   ],
   "metadata": {
    "id": "CwVrT9Z1YOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image = test_image / 255.0"
   ],
   "metadata": {
    "id": "kYeWf7IQYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image.shape"
   ],
   "metadata": {
    "id": "WHajQBvOYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test_image = np.expand_dims(test_image, axis=0)\n"
   ],
   "metadata": {
    "id": "Yb74G7MaYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prediction = image_model.predict(test_image)\n"
   ],
   "metadata": {
    "id": "YKPvxeTZYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prediction[0][0]"
   ],
   "metadata": {
    "id": "lb_6_0sJYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "scores = tf.nn.softmax(prediction[0])\n",
    "scores = scores.numpy()"
   ],
   "metadata": {
    "id": "S_0dwBLXYOGg",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "base_dir = 'food-101/images'\n",
    "class_names = os.listdir(base_dir)\n",
    "f\"{class_names[np.argmax(scores)]} with a { (100 * np.max(scores)).round(2) } percent confidence.\" "
   ],
   "metadata": {
    "id": "DhlDdwn5YOGh",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}