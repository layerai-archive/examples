{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbl_5GrpV_Qd"
      },
      "source": [
        "# Fine tuning T5 with Layer\n",
        "\n",
        "[![Open In Layer](https://app.layer.ai/assets/badge.svg)](https://app.layer.ai/layer/named-entity-recognition) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Kx4-BpHaIjp5C6AkHW_T2jZM_Azy0xzk#scrollTo=hbl_5GrpV_Qd)\n",
        "\n",
        "A T5 is an encoder-decoder model. It converts all NLP problems like language translation, summarization, text generation, question-answering, to a text-to-text task.\n",
        "\n",
        "We are going to fine tune a pretrained T5 Model from ü§ó and train it to do named entity recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTOTXBFNKqhb"
      },
      "source": [
        "# Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkjmRTy_VQ72"
      },
      "outputs": [],
      "source": [
        "!pip install ipython ipykernel --upgrade -q\n",
        "!pip install layer-sdk --upgrade -q\n",
        "!pip install sentencepiece -q\n",
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZPKqz1aHjDc"
      },
      "source": [
        "# Getting Started with Layer\n",
        "\n",
        "Layer is an MLOps platform which advances ML pipelines with remote computation and tracking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4eVYhZ8K-Kf"
      },
      "source": [
        "## Login to Layer\n",
        "\n",
        "Let's login to Layer first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW6owUH0VWe-"
      },
      "outputs": [],
      "source": [
        "import layer\n",
        "layer.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vgj3JHo-JeNv"
      },
      "source": [
        "## Initialize Layer Project\n",
        "Now we are ready to init our project. A Layer Project is basically an ML Repo hosted on Layer where you can store your datasets, models and metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s6mpaMtGDUv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezPdWXBXVlBP",
        "outputId": "8521731c-95f9-4efd-fddf-ad4dc039f13e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Project(name='named-entity-recognition', raw_datasets=[], derived_datasets=[], featuresets=[], models=[], path=PosixPath('.'), project_files_hash='', readme='', organization=Organization(id=UUID('d7325da3-0646-4fa6-855d-8d19eece8b79'), name='layer'), _id=UUID('7653821a-53c6-44b9-8b91-248e6a53f225'), functions=[])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "layer.init(\"named-entity-recognition\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xos7VwStJq_F"
      },
      "source": [
        "Your project is ready. Find your project here:\n",
        "\n",
        "https://app.layer.ai/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63lSAPAiWeyz"
      },
      "source": [
        "# Upload training data\n",
        "Fetch CoNLL 2003 data, convert it into a format for T5 and save it to the Layer backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "11a6a9a17d2f45fc8c46443063a26aa2",
            "7167536925d74748b21cd1e7bf829c80",
            "2d9c442f70ce44b691ce44b95de47201",
            "a6a9a54d36674ba59a6280c98d146e32",
            "10ac08a6beb84c40aebe278aaacc0baa",
            "0af47b881737426fb962b1ca3a632d9d"
          ]
        },
        "id": "Ablj8OlgWlC2",
        "outputId": "401ca520-3fed-4926-93ea-3dce205cf341"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11a6a9a17d2f45fc8c46443063a26aa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d9c442f70ce44b691ce44b95de47201"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10ac08a6beb84c40aebe278aaacc0baa"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "from layer.decorators import dataset\n",
        "from layer.client import Dataset\n",
        "\n",
        "def transform_raw_dataset(input_df):\n",
        "  rows = []\n",
        "  for index, row in input_df.iterrows():\n",
        "    tokens = json.loads(row['tokens'])\n",
        "    ner_tags = json.loads(row['ner_tags'])\n",
        "\n",
        "    ner_tokens = []\n",
        "    for token, ner_tag in zip(tokens, ner_tags):\n",
        "      if ner_tag == 'O':\n",
        "        ner_tokens.append(token)\n",
        "      else:\n",
        "        ner_tokens.append(f'{token}|{ner_tag}')\n",
        "\n",
        "    rows.append([' '.join(tokens), ' '.join(ner_tokens)])\n",
        "    \n",
        "  df = pd.DataFrame(rows, columns=[\"sentence\", \"entities\"])\n",
        "  return df\n",
        "\n",
        "\n",
        "for DATA_TYPE in ['train', 'validation', 'test']:\n",
        "  @dataset(f\"t5_ner_{DATA_TYPE}_data\", dependencies=[Dataset(f\"layer/conll2003/datasets/{DATA_TYPE}\")])\n",
        "  def build_dataset():\n",
        "    return transform_raw_dataset(layer.get_dataset(f\"layer/conll2003/datasets/{DATA_TYPE}\").to_pandas())\n",
        "  build_dataset()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhDn_iW5NLyt"
      },
      "source": [
        "# Fine Tune T5\n",
        "\n",
        "Our dataset is ready and registered to Layer. Now we are going to develop the fine tuning logic, decorate the function with `@model` and pass it to Layer so that it can be run on Layer infra and registered under our project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r51__wGKjWhq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from layer.client import Dataset\n",
        "\n",
        "\n",
        "class NERDataSet(Dataset):\n",
        "\n",
        "  def __init__(self, dataframe, tokenizer, source_len, target_len, source_text, target_text):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data = dataframe\n",
        "    self.source_len = source_len\n",
        "    self.summ_len = target_len\n",
        "    self.target_text = self.data[target_text]\n",
        "    self.source_text = self.data[source_text]\n",
        "\n",
        "    self.data[\"sentence\"] = \"recognize named entities: \"+self.data[\"sentence\"]\n",
        "    self.data[\"entities\"] = \"<pad>\" + self.data[\"entities\"] + \"</s>\"\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.target_text)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    source_text = str(self.source_text[index])\n",
        "    target_text = str(self.target_text[index])\n",
        "\n",
        "    source_text = ' '.join(source_text.split())\n",
        "    target_text = ' '.join(target_text.split())\n",
        "\n",
        "    source = self.tokenizer.batch_encode_plus([source_text], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
        "    target = self.tokenizer.batch_encode_plus([target_text], max_length= self.summ_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n",
        "\n",
        "    source_ids = source['input_ids'].squeeze()\n",
        "    source_mask = source['attention_mask'].squeeze()\n",
        "    target_ids = target['input_ids'].squeeze()\n",
        "    target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "    return {\n",
        "        'source_ids': source_ids.to(dtype=torch.long),\n",
        "        'source_mask': source_mask.to(dtype=torch.long),\n",
        "        'target_ids': target_ids.to(dtype=torch.long),\n",
        "        'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUxkIObxoh8j"
      },
      "outputs": [],
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "  import torch\n",
        "  \n",
        "  model.train()\n",
        "  for _,data in enumerate(loader, 0):\n",
        "    y = data['target_ids'].to(device, dtype = torch.long)\n",
        "    y_ids = y[:, :-1].contiguous()\n",
        "    lm_labels = y[:, 1:].clone().detach()\n",
        "    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "    ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "    mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "    loss = outputs[0]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqA2YcZ8NdKS"
      },
      "source": [
        "Here we use 3 seperate Layer decorators:\n",
        "- [`@model`](https://docs.app.layer.ai/docs/sdk-library/model-decorator): Tells Layer that this function trains an ML model\n",
        "- [`@fabric`](https://docs.app.layer.ai/docs/sdk-library/fabric-decorator): Tells Layer the computation resources (cpu, gpu etc.) needed to train the model. Here is a list of the [available fabrics](https://docs.development.layer.co/docs/reference/fabrics) you can use.\n",
        "- [`@pip_requirements`](https://docs.app.layer.ai/docs/sdk-library/pip-requirements-decorator): Tells the pypi libraries needed to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQYIvpAFoo2-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320,
          "referenced_widgets": [
            "1c611916756c46b6be03d0968ba2e2a9",
            "a408bb4193b94147b1c67ea0a9804c51"
          ]
        },
        "outputId": "009ef8f8-6831-42fc-aabf-03f1f6ae6c2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c611916756c46b6be03d0968ba2e2a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Model]: Loading model t5-small for device cuda...\n",
            "\n",
            "[Data]: Reading data...\n",
            "\n",
            "TRAIN Dataset: (2000, 2)\n",
            "VALID Dataset: (400, 2)\n",
            "TEST Dataset: (400, 2)\n",
            "[Initiating Fine Tuning]...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/t5/tokenization_t5.py:195: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Saving Model]...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from layer.decorators import model, pip_requirements, fabric\n",
        "from layer.client import Dataset, Model\n",
        "\n",
        "MODEL_PARAMS={\n",
        "    \"MODEL\":\"t5-small\",            \n",
        "    \"TRAIN_BATCH_SIZE\":8,          \n",
        "    \"VALID_BATCH_SIZE\":8,          \n",
        "    \"TRAIN_EPOCHS\":3,              \n",
        "    \"VAL_EPOCHS\":3,\n",
        "    \"LEARNING_RATE\":1e-4,          \n",
        "    \"MAX_SOURCE_TEXT_LENGTH\":75,   \n",
        "    \"MAX_TARGET_TEXT_LENGTH\":75, \n",
        "    \"MAX_TRAINING_ROWS\":2000,\n",
        "    \"SEED\": 33\n",
        "}\n",
        "\n",
        "@model(\"t5-named-entity-recognition\", \n",
        "       dependencies=[\n",
        "                     Model(f\"layer/t5/models/{MODEL_PARAMS['MODEL']}\"),\n",
        "                     Model(f\"layer/t5/models/{MODEL_PARAMS['MODEL']}-tokenizer\"),\n",
        "                     Dataset(\"t5_ner_train_data\"),\n",
        "                     Dataset(\"t5_ner_validation_data\"),\n",
        "                     Dataset(\"t5_ner_test_data\"),\n",
        "                     ])\n",
        "@fabric(\"f-medium\")\n",
        "@pip_requirements(packages=[\"numpy\", \"torch\", \"transformers\", \"sentencepiece\"])\n",
        "def build_model():\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  import torch.nn.functional as F\n",
        "  from torch import cuda\n",
        "  from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "  # # Set random seeds and deterministic pytorch for reproducibility\n",
        "  torch.manual_seed(MODEL_PARAMS[\"SEED\"]) # pytorch random seed\n",
        "  np.random.seed(MODEL_PARAMS[\"SEED\"]) # numpy random seed\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  # Setting up the device for GPU usage\n",
        "  device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "  # Load pretrained model from Layer\n",
        "  print(f\"\"\"[Model]: Loading model {MODEL_PARAMS['MODEL']} for device {device}...\\n\"\"\")\n",
        "\n",
        "  model = layer.get_model(f\"layer/t5/models/{MODEL_PARAMS['MODEL']}\").get_train()\n",
        "  model.to(device)\n",
        "\n",
        "  # Load tokenizer\n",
        "  tokenizer = layer.get_model(f\"layer/t5/models/{MODEL_PARAMS['MODEL']}-tokenizer\").get_train()\n",
        "\n",
        "  # Read data\n",
        "  print(f\"[Data]: Reading data...\\n\")\n",
        "  \n",
        "  train_df = layer.get_dataset(\"t5_ner_train_data\").to_pandas().head(MODEL_PARAMS['MAX_TRAINING_ROWS'])\n",
        "  valid_df = layer.get_dataset(\"t5_ner_validation_data\").to_pandas().head(MODEL_PARAMS['MAX_TRAINING_ROWS']//5)\n",
        "  test_df = layer.get_dataset(\"t5_ner_test_data\").to_pandas().head(MODEL_PARAMS['MAX_TRAINING_ROWS']//5)\n",
        "  source_text = \"sentence\"\n",
        "  target_text = \"entities\"\n",
        "\n",
        "  # Creation of Dataset and Dataloader\n",
        "  # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n",
        "  print(f\"TRAIN Dataset: {train_df.shape}\")\n",
        "  print(f\"VALID Dataset: {valid_df.shape}\")\n",
        "  print(f\"TEST Dataset: {test_df.shape}\")\n",
        "\n",
        "  # Creating the Training and Validation dataset for further creation of Dataloader\n",
        "  train_set = NERDataSet(train_df, tokenizer, MODEL_PARAMS[\"MAX_SOURCE_TEXT_LENGTH\"], MODEL_PARAMS[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
        "  valid_set = NERDataSet(valid_df, tokenizer, MODEL_PARAMS[\"MAX_SOURCE_TEXT_LENGTH\"], MODEL_PARAMS[\"MAX_TARGET_TEXT_LENGTH\"], source_text, target_text)\n",
        "\n",
        "  # Defining the parameters for creation of dataloaders\n",
        "  train_params = {\n",
        "      'batch_size': MODEL_PARAMS[\"TRAIN_BATCH_SIZE\"],\n",
        "      'shuffle': True,\n",
        "      'num_workers': 0\n",
        "      }\n",
        "\n",
        "  valid_params = {\n",
        "      'batch_size': MODEL_PARAMS[\"VALID_BATCH_SIZE\"],\n",
        "      'shuffle': False,\n",
        "      'num_workers': 0\n",
        "      }\n",
        "\n",
        "\n",
        "  # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
        "  training_loader = DataLoader(train_set, **train_params)\n",
        "  val_loader = DataLoader(valid_set, **valid_params)\n",
        "\n",
        "\n",
        "  # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
        "  optimizer = torch.optim.Adam(params =  model.parameters(), lr=MODEL_PARAMS[\"LEARNING_RATE\"])\n",
        "\n",
        "\n",
        "  # Training loop\n",
        "  print(f'[Initiating Fine Tuning]...\\n')\n",
        "\n",
        "  for epoch in range(MODEL_PARAMS[\"TRAIN_EPOCHS\"]):\n",
        "      train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
        "\n",
        "  print(f\"[Saving Model]...\\n\")\n",
        "\n",
        "  return model\n",
        "\n",
        "build_model()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "T5 - Fine Tuning for Named Entity Recognition",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "11a6a9a17d2f45fc8c46443063a26aa2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_7167536925d74748b21cd1e7bf829c80",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "‚úÖ  t5_ner_train_data    \u001b[38;2;52;211;153m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:31\u001b[0m\u001b[39m ]\u001b[0m          \n    \u001b]8;id=45931;https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_train_data\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_train_data\u001b[0m\u001b]8;;\u001b\\ \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ  t5_ner_train_data    <span style=\"color: #34d399; text-decoration-color: #34d399\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:31</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>          \n    <a href=\"https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_train_data\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_train_data</span></a> \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "7167536925d74748b21cd1e7bf829c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d9c442f70ce44b691ce44b95de47201": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a6a9a54d36674ba59a6280c98d146e32",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "‚úÖ  t5_ner_validation_d‚Ä¶ \u001b[38;2;52;211;153m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:24\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=43904;https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_validation_data\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_validation_d\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=43904;https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_validation_data\u001b\\\u001b[4;38;2;161;161;169mata\u001b[0m\u001b]8;;\u001b\\                                                                                      \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ  t5_ner_validation_d‚Ä¶ <span style=\"color: #34d399; text-decoration-color: #34d399\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:24</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_validation_data\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_validation_d</span></a> \n    <a href=\"https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_validation_data\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">ata</span></a>                                                                                      \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "a6a9a54d36674ba59a6280c98d146e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10ac08a6beb84c40aebe278aaacc0baa": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0af47b881737426fb962b1ca3a632d9d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "‚úÖ  t5_ner_test_data     \u001b[38;2;52;211;153m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:00:24\u001b[0m\u001b[39m ]\u001b[0m         \n    \u001b]8;id=184823;https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_test_data\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_test_data\u001b[0m\u001b]8;;\u001b\\ \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ  t5_ner_test_data     <span style=\"color: #34d399; text-decoration-color: #34d399\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:00:24</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>         \n    <a href=\"https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_test_data\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/named-entity-recognition/datasets/t5_ner_test_data</span></a> \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "0af47b881737426fb962b1ca3a632d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c611916756c46b6be03d0968ba2e2a9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a408bb4193b94147b1c67ea0a9804c51",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "‚úÖ  t5-named-entity-rec‚Ä¶ \u001b[38;2;52;211;153m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[38;2;52;211;153m        done         \u001b[0m \u001b[39m[ \u001b[0m\u001b[33m0:02:03\u001b[0m\u001b[39m ]\u001b[0m            \n    \u001b]8;id=154947;https://app.layer.ai/layer/named-entity-recognition/models/t5-named-entity-recognition\u001b\\\u001b[4;38;2;161;161;169mhttps://app.layer.ai/layer/named-entity-recognition/models/t5-named-entity-recog\u001b[0m\u001b]8;;\u001b\\ \n    \u001b]8;id=154947;https://app.layer.ai/layer/named-entity-recognition/models/t5-named-entity-recognition\u001b\\\u001b[4;38;2;161;161;169mnition\u001b[0m\u001b]8;;\u001b\\                                                                                   \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚úÖ  t5-named-entity-rec‚Ä¶ <span style=\"color: #34d399; text-decoration-color: #34d399\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\"color: #34d399; text-decoration-color: #34d399\">        done         </span> <span style=\"color: #000000; text-decoration-color: #000000\">[ </span><span style=\"color: #808000; text-decoration-color: #808000\">0:02:03</span><span style=\"color: #000000; text-decoration-color: #000000\"> ]</span>            \n    <a href=\"https://app.layer.ai/layer/named-entity-recognition/models/t5-named-entity-recognition\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">https://app.layer.ai/layer/named-entity-recognition/models/t5-named-entity-recog</span></a> \n    <a href=\"https://app.layer.ai/layer/named-entity-recognition/models/t5-named-entity-recognition\"><span style=\"color: #a1a1a9; text-decoration-color: #a1a1a9; text-decoration: underline\">nition</span></a>                                                                                   \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "a408bb4193b94147b1c67ea0a9804c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}